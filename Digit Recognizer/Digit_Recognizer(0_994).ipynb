{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZNXel3R7Zg0cVhKY6fRpzwdhzYIJZXGI",
      "authorship_tag": "ABX9TyOeL5YgIoLOvhXZ5/UKy/DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlwogns/ML-DL/blob/main/Digit%20Recognizer/Digit_Recognizer(0_994).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Tkk3v61viL8e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/digit-recognizer/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/digit-recognizer/test.csv\")"
      ],
      "metadata": {
        "id": "oCOCfobni2j2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train[\"label\"]\n",
        "X_train = train.drop(labels=[\"label\"], axis=1)"
      ],
      "metadata": {
        "id": "X5JHdFMckMLZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255.0\n",
        "test = test/255.0"
      ],
      "metadata": {
        "id": "u79mRAY_knpR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1, 28,28,1)\n",
        "# reshape에 -1이 들어가면 \"원래 배열의 길이와 남은 차원으로 부터 추정\"의 의미로, auto랑 비슷하게 쓰면 되는거 같음.\n",
        "# 28 * 28 * 1의 3차원으로 만드는 이유는 CNN의 구조 때문."
      ],
      "metadata": {
        "id": "XVNHAFPglJdN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)"
      ],
      "metadata": {
        "id": "mlrdZtzLmyQ3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split training and validiation set\n",
        "X_train, X_val, Y_train , Y_val = train_test_split(X_train, y_train, test_size = 0.1)"
      ],
      "metadata": {
        "id": "KrzYctpioCba"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0][:,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "x7De9prCpc-m",
        "outputId": "af6db3ab-8f7c-4582-a1f6-ae07eb250041"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fabcb29cbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "# for avoiding overfitting\n",
        "# 1. Data Augmentation\n",
        "# 2. Dropout\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False\n",
        ")\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "-n6JIrE3hC2H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early Stopping\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)"
      ],
      "metadata": {
        "id": "DPgF-iz3m_go"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 30\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "-ioGgA3Wp1Ij"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.model = tf.keras.Sequential()\n",
        "# Conv2D filter에 대하여\n",
        "# https://www.youtube.com/watch?v=aircAruvnKk&embeds_euri=https%3A%2F%2F89douner.tistory.com%2F57&feature=emb_imp_woyt\n",
        "# filters는 각 이미지에서 edge에 대한 정보를 얼마나 가져올 것 인지를 의미한다.\n",
        "# 개수는 임의로 지정하는 것이며, 보통 16, 32 등 2^를 많이 사용하는 것 같은데 왜그런지 찾고있다.\n",
        "# filter의 개수가 input의 개수와 같으면 FNN으로 일반적인 DNN과 같다.\n",
        "# CNN의 장점이 DNN보다 인자가 현저히 작다는 것이다. conv2d와 maxpooling을 이용해 특징을 기반으로 이미지를 분류하기 때문이다.(위의 동영상 참조)"
      ],
      "metadata": {
        "id": "YGosluOZqGwh"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#layer 1\n",
        "tf.model.add(Conv2D(filters=32, kernel_size = (5,5), input_shape=(28,28,1), activation='relu'))\n",
        "tf.model.add(Conv2D(filters=32, kernel_size = (5,5), input_shape=(28,28,1), activation='relu'))\n",
        "tf.model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "tf.model.add(Dropout(0.5))"
      ],
      "metadata": {
        "id": "c0R9PxGhqIhG"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#layer 2\n",
        "tf.model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
        "tf.model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\n",
        "tf.model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "tf.model.add(Dropout(0.5))"
      ],
      "metadata": {
        "id": "2yo-UV_Hqn8M"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#layer 3\n",
        "tf.model.add(Flatten())\n",
        "tf.model.add(Dense(units=10, kernel_initializer='glorot_normal', activation='softmax'))"
      ],
      "metadata": {
        "id": "JT7LG_t4q-Ro"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(lr = learning_rate), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5IFde98rIYx",
        "outputId": "5822d3fa-6dd7-4877-cf6b-93e69d6a8db7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3vKIkBorUXL",
        "outputId": "9eb651ad-452b-4233-8e02-7c7731be9982"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 20, 20, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 10, 10, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 10, 10, 32)        0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 64)          18496     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 6, 6, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                5770      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,658\n",
            "Trainable params: 87,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#history = tf.model.fit(X_train, Y_train, batch_size = batch_size, epochs = training_epochs)\n",
        "# generator를 사용하여 추가 데이터를 만들었기 때문에, fit_generator를 사용.\n",
        "history = tf.model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size),\n",
        "                                 epochs = training_epochs, validation_data = (X_val, Y_val), callbacks=[callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxEQA-zfrWF_",
        "outputId": "bacb89fe-f528-4b13-aa7d-aca27819db6b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-105-c164070ce418>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = tf.model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "296/296 [==============================] - 12s 39ms/step - loss: 0.7905 - accuracy: 0.7365 - val_loss: 0.1069 - val_accuracy: 0.9707\n",
            "Epoch 2/30\n",
            "296/296 [==============================] - 13s 43ms/step - loss: 0.2618 - accuracy: 0.9222 - val_loss: 0.0725 - val_accuracy: 0.9776\n",
            "Epoch 3/30\n",
            "296/296 [==============================] - 12s 40ms/step - loss: 0.1775 - accuracy: 0.9458 - val_loss: 0.0533 - val_accuracy: 0.9836\n",
            "Epoch 4/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.1433 - accuracy: 0.9566 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
            "Epoch 5/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.1261 - accuracy: 0.9612 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
            "Epoch 6/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.1145 - accuracy: 0.9651 - val_loss: 0.0364 - val_accuracy: 0.9881\n",
            "Epoch 7/30\n",
            "296/296 [==============================] - 11s 38ms/step - loss: 0.1035 - accuracy: 0.9693 - val_loss: 0.0350 - val_accuracy: 0.9876\n",
            "Epoch 8/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0898 - accuracy: 0.9720 - val_loss: 0.0346 - val_accuracy: 0.9886\n",
            "Epoch 9/30\n",
            "296/296 [==============================] - 12s 40ms/step - loss: 0.0900 - accuracy: 0.9736 - val_loss: 0.0327 - val_accuracy: 0.9900\n",
            "Epoch 10/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0844 - accuracy: 0.9757 - val_loss: 0.0281 - val_accuracy: 0.9910\n",
            "Epoch 11/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0793 - accuracy: 0.9764 - val_loss: 0.0292 - val_accuracy: 0.9910\n",
            "Epoch 12/30\n",
            "296/296 [==============================] - 11s 38ms/step - loss: 0.0756 - accuracy: 0.9769 - val_loss: 0.0300 - val_accuracy: 0.9900\n",
            "Epoch 13/30\n",
            "296/296 [==============================] - 13s 44ms/step - loss: 0.0735 - accuracy: 0.9779 - val_loss: 0.0283 - val_accuracy: 0.9895\n",
            "Epoch 14/30\n",
            "296/296 [==============================] - 11s 38ms/step - loss: 0.0704 - accuracy: 0.9798 - val_loss: 0.0263 - val_accuracy: 0.9919\n",
            "Epoch 15/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0234 - val_accuracy: 0.9921\n",
            "Epoch 16/30\n",
            "296/296 [==============================] - 11s 38ms/step - loss: 0.0644 - accuracy: 0.9804 - val_loss: 0.0230 - val_accuracy: 0.9931\n",
            "Epoch 17/30\n",
            "296/296 [==============================] - 12s 40ms/step - loss: 0.0600 - accuracy: 0.9825 - val_loss: 0.0229 - val_accuracy: 0.9921\n",
            "Epoch 18/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0607 - accuracy: 0.9822 - val_loss: 0.0225 - val_accuracy: 0.9924\n",
            "Epoch 19/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.0585 - accuracy: 0.9819 - val_loss: 0.0187 - val_accuracy: 0.9945\n",
            "Epoch 20/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0616 - accuracy: 0.9821 - val_loss: 0.0291 - val_accuracy: 0.9902\n",
            "Epoch 21/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0588 - accuracy: 0.9829 - val_loss: 0.0258 - val_accuracy: 0.9921\n",
            "Epoch 22/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 0.0265 - val_accuracy: 0.9924\n",
            "Epoch 23/30\n",
            "296/296 [==============================] - 12s 40ms/step - loss: 0.0526 - accuracy: 0.9846 - val_loss: 0.0229 - val_accuracy: 0.9931\n",
            "Epoch 24/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.0509 - accuracy: 0.9855 - val_loss: 0.0246 - val_accuracy: 0.9919\n",
            "Epoch 25/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.0519 - accuracy: 0.9845 - val_loss: 0.0230 - val_accuracy: 0.9924\n",
            "Epoch 26/30\n",
            "296/296 [==============================] - 13s 43ms/step - loss: 0.0480 - accuracy: 0.9855 - val_loss: 0.0162 - val_accuracy: 0.9950\n",
            "Epoch 27/30\n",
            "296/296 [==============================] - 12s 40ms/step - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.0201 - val_accuracy: 0.9931\n",
            "Epoch 28/30\n",
            "296/296 [==============================] - 11s 39ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 0.0250 - val_accuracy: 0.9929\n",
            "Epoch 29/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.0191 - val_accuracy: 0.9940\n",
            "Epoch 30/30\n",
            "296/296 [==============================] - 12s 39ms/step - loss: 0.0484 - accuracy: 0.9858 - val_loss: 0.0196 - val_accuracy: 0.9945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation = tf.model.evaluate(X_val, Y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_nwvHOwrsjt",
        "outputId": "d213ea06-9b92-4b06-f12c-5d3f15ebbb9f"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = tf.model.predict(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUVq76LtpEC",
        "outputId": "e61a7e08-2ef2-42d1-8840-cb76fe31fbf4"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875/875 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = np.argmax(result, axis=1)"
      ],
      "metadata": {
        "id": "kpNUdQu1txEM"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.Series(results, name=\"Label\")"
      ],
      "metadata": {
        "id": "h5aKs9i3t0kj"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "\n",
        "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
      ],
      "metadata": {
        "id": "kl4887i2t6aH"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QzKKNHxlgVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}